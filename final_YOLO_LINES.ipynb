{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\UCU\\Course_3\\AI\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from timeit import default_timer as timer\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob,os\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.misc import imresize\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load visuaizations.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_lane_status(frame, lane_info, threshold_offset = 0.6):\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    info_road = \"Lane Status\"\n",
    "    info_lane = \"Direction: {0}\".format(lane_info['curve_direction'])\n",
    "    info_cur = \"Curvature {:6.1f} m\".format(lane_info['curvature'])\n",
    "    info_offset = \"Off center: {0} {1:3.1f}m\".format(lane_info['dev_dir'], lane_info['offset'])\n",
    "\n",
    "    l_uper = (10,10)\n",
    "\n",
    "    cv2.line(frame,(l_uper[0] + 265,0),(l_uper[0] + 265,155),(255,0,0),5)\n",
    "\n",
    "    cv2.putText(frame, info_road, (50,32+5), font, 0.8, (255,255,0), 2,cv2.LINE_AA)\n",
    "    cv2.putText(frame, info_lane, (16,60+10), font, 0.6, (255,255,0), 1,cv2.LINE_AA)\n",
    "    cv2.putText(frame, info_cur, (16,80+25), font, 0.6, (255,255,0), 1,cv2.LINE_AA)\n",
    "\n",
    "    if lane_info['offset'] >= threshold_offset:\n",
    "        cv2.putText(frame, info_offset, (16,100+40), font, 0.6, (255,0,0), 1,cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(frame, info_offset, (16,100+40), font, 0.6, (255,255,0), 1,cv2.LINE_AA)\n",
    "\n",
    "def draw_speed(img_cp, fps, w):\n",
    "\n",
    "    fps_info = \"{0:4.1f} fps\".format(fps)\n",
    "    cv2.putText(img_cp, 'Speed', (w - 120,37), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img_cp, fps_info, (w - 130,100), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,0), 1, cv2.LINE_AA)\n",
    "    cv2.line(img_cp,(w-160,0),(w-160,155),(255,0,0),5)\n",
    "\n",
    "\n",
    "def draw_thumbnails(img_cp, img, window_list, thumb_w=100, thumb_h=80, off_x=30, off_y=30):\n",
    "\n",
    "    cv2.putText(img_cp, 'Detected viehicles', (400,37), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,0), 2, cv2.LINE_AA)\n",
    "    for i, bbox in enumerate(window_list):\n",
    "        thumbnail = img[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]]\n",
    "        vehicle_thumb = cv2.resize(thumbnail, dsize=(thumb_w, thumb_h))\n",
    "        start_x = 300 + (i+1) * off_x + i * thumb_w\n",
    "        img_cp[off_y + 30:off_y + thumb_h + 30, start_x:start_x + thumb_w, :] = vehicle_thumb\n",
    "\n",
    "\n",
    "def draw_background_highlight(image, draw_img, w):\n",
    "\n",
    "    mask = cv2.rectangle(np.copy(image), (0, 0), (w, 155), (0, 0, 0), thickness=cv2.FILLED)\n",
    "    draw_img = cv2.addWeighted(src1=mask, alpha=0.3, src2=draw_img, beta=0.8, gamma=0)\n",
    "\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building YOLO_small graph...\n",
      "Layer  1 : Type = Conv, Size = 7 * 7, Stride = 2, Filters = 64, Input channels = 3\n",
      "Layer  2 : Type = Pool, Size = 2 * 2, Stride = 2\n",
      "Layer  3 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 192, Input channels = 64\n",
      "Layer  4 : Type = Pool, Size = 2 * 2, Stride = 2\n",
      "Layer  5 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 128, Input channels = 192\n",
      "Layer  6 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 256, Input channels = 128\n",
      "Layer  7 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 256, Input channels = 256\n",
      "Layer  8 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 512, Input channels = 256\n",
      "Layer  9 : Type = Pool, Size = 2 * 2, Stride = 2\n",
      "Layer  10 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 256, Input channels = 512\n",
      "Layer  11 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 512, Input channels = 256\n",
      "Layer  12 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 256, Input channels = 512\n",
      "Layer  13 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 512, Input channels = 256\n",
      "Layer  14 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 256, Input channels = 512\n",
      "Layer  15 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 512, Input channels = 256\n",
      "Layer  16 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 256, Input channels = 512\n",
      "Layer  17 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 512, Input channels = 256\n",
      "Layer  18 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 512, Input channels = 512\n",
      "Layer  19 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 1024, Input channels = 512\n",
      "Layer  20 : Type = Pool, Size = 2 * 2, Stride = 2\n",
      "Layer  21 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 512, Input channels = 1024\n",
      "Layer  22 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 1024, Input channels = 512\n",
      "Layer  23 : Type = Conv, Size = 1 * 1, Stride = 1, Filters = 512, Input channels = 1024\n",
      "Layer  24 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 1024, Input channels = 512\n",
      "Layer  25 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 1024, Input channels = 1024\n",
      "Layer  26 : Type = Conv, Size = 3 * 3, Stride = 2, Filters = 1024, Input channels = 1024\n",
      "Layer  27 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 1024, Input channels = 1024\n",
      "Layer  28 : Type = Conv, Size = 3 * 3, Stride = 1, Filters = 1024, Input channels = 1024\n",
      "Layer  29 : Type = Full, Hidden = 512, Input dimension = 50176, Flat = 1, Activation = 1\n",
      "Layer  30 : Type = Full, Hidden = 4096, Input dimension = 512, Flat = 0, Activation = 1\n",
      "Layer  32 : Type = Full, Hidden = 1470, Input dimension = 4096, Flat = 0, Activation = 0\n",
      "INFO:tensorflow:Restoring parameters from YOLO_small.ckpt\n",
      "Loading complete!\n"
     ]
    }
   ],
   "source": [
    "# %load \"python prog/yolo_pipeline.py\"\n",
    "# import numpy as np\n",
    "import tensorflow as tf\n",
    "# import cv2\n",
    "from timeit import default_timer as timer\n",
    "# import time\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "class yolo_tf:\n",
    "    w_img = 1280\n",
    "    h_img = 720\n",
    "\n",
    "    weights_file = 'YOLO_small.ckpt'\n",
    "    alpha = 0.1\n",
    "    threshold = 0.3\n",
    "    iou_threshold = 0.5\n",
    "\n",
    "    result_list = None\n",
    "    classes =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\",\n",
    "                \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "                \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.build_networks()\n",
    "\n",
    "    def build_networks(self):\n",
    "        print(\"Building YOLO_small graph...\")\n",
    "        self.x = tf.placeholder('float32',[None,448,448,3])\n",
    "        # self.x = tf.placeholder('float32',[None,252, 1280, 3])\n",
    "        self.conv_1 = self.conv_layer(1,self.x,64,7,2)\n",
    "        self.pool_2 = self.pooling_layer(2,self.conv_1,2,2)\n",
    "        self.conv_3 = self.conv_layer(3,self.pool_2,192,3,1)\n",
    "        self.pool_4 = self.pooling_layer(4,self.conv_3,2,2)\n",
    "        self.conv_5 = self.conv_layer(5,self.pool_4,128,1,1)\n",
    "        self.conv_6 = self.conv_layer(6,self.conv_5,256,3,1)\n",
    "        self.conv_7 = self.conv_layer(7,self.conv_6,256,1,1)\n",
    "        self.conv_8 = self.conv_layer(8,self.conv_7,512,3,1)\n",
    "        self.pool_9 = self.pooling_layer(9,self.conv_8,2,2)\n",
    "        self.conv_10 = self.conv_layer(10,self.pool_9,256,1,1)\n",
    "        self.conv_11 = self.conv_layer(11,self.conv_10,512,3,1)\n",
    "        self.conv_12 = self.conv_layer(12,self.conv_11,256,1,1)\n",
    "        self.conv_13 = self.conv_layer(13,self.conv_12,512,3,1)\n",
    "        self.conv_14 = self.conv_layer(14,self.conv_13,256,1,1)\n",
    "        self.conv_15 = self.conv_layer(15,self.conv_14,512,3,1)\n",
    "        self.conv_16 = self.conv_layer(16,self.conv_15,256,1,1)\n",
    "        self.conv_17 = self.conv_layer(17,self.conv_16,512,3,1)\n",
    "        self.conv_18 = self.conv_layer(18,self.conv_17,512,1,1)\n",
    "        self.conv_19 = self.conv_layer(19,self.conv_18,1024,3,1)\n",
    "        self.pool_20 = self.pooling_layer(20,self.conv_19,2,2)\n",
    "        self.conv_21 = self.conv_layer(21,self.pool_20,512,1,1)\n",
    "        self.conv_22 = self.conv_layer(22,self.conv_21,1024,3,1)\n",
    "        self.conv_23 = self.conv_layer(23,self.conv_22,512,1,1)\n",
    "        self.conv_24 = self.conv_layer(24,self.conv_23,1024,3,1)\n",
    "        self.conv_25 = self.conv_layer(25,self.conv_24,1024,3,1)\n",
    "        self.conv_26 = self.conv_layer(26,self.conv_25,1024,3,2)\n",
    "        self.conv_27 = self.conv_layer(27,self.conv_26,1024,3,1)\n",
    "        self.conv_28 = self.conv_layer(28,self.conv_27,1024,3,1)\n",
    "        self.fc_29 = self.fc_layer(29,self.conv_28,512,flat=True,linear=False)\n",
    "        self.fc_30 = self.fc_layer(30,self.fc_29,4096,flat=False,linear=False)\n",
    "        #skip dropout_31\n",
    "        self.fc_32 = self.fc_layer(32, self.fc_30, 1470, flat=False, linear=True)\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.saver.restore(self.sess, self.weights_file)\n",
    "        print(\"Loading complete!\")\n",
    "\n",
    "    def conv_layer(self,idx,inputs,filters,size,stride):\n",
    "        channels = inputs.get_shape()[3]\n",
    "        weight = tf.Variable(tf.truncated_normal([size,size,int(channels),filters], stddev=0.1))\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[filters]))\n",
    "\n",
    "        pad_size = size//2\n",
    "        pad_mat = np.array([[0,0],[pad_size,pad_size],[pad_size,pad_size],[0,0]])\n",
    "        inputs_pad = tf.pad(inputs,pad_mat)\n",
    "\n",
    "        conv = tf.nn.conv2d(inputs_pad, weight, strides=[1, stride, stride, 1], padding='VALID',name=str(idx)+'_conv')\n",
    "        conv_biased = tf.add(conv,biases,name=str(idx)+'_conv_biased')\n",
    "        print('Layer  %d : Type = Conv, Size = %d * %d, Stride = %d, Filters = %d, Input channels = %d' % (idx,size,size,stride,filters,int(channels)))\n",
    "        return tf.maximum(self.alpha*conv_biased,conv_biased,name=str(idx)+'_leaky_relu')\n",
    "\n",
    "    def pooling_layer(self,idx,inputs,size,stride):\n",
    "        print ('Layer  %d : Type = Pool, Size = %d * %d, Stride = %d' % (idx,size,size,stride))\n",
    "        return tf.nn.max_pool(inputs, ksize=[1, size, size, 1],strides=[1, stride, stride, 1], padding='SAME',name=str(idx)+'_pool')\n",
    "\n",
    "    def fc_layer(self,idx,inputs,hiddens,flat = False,linear = False):\n",
    "        input_shape = inputs.get_shape().as_list()\n",
    "        if flat:\n",
    "            dim = input_shape[1]*input_shape[2]*input_shape[3]\n",
    "            inputs_transposed = tf.transpose(inputs,(0,3,1,2))\n",
    "            inputs_processed = tf.reshape(inputs_transposed, [-1,dim])\n",
    "        else:\n",
    "            dim = input_shape[1]\n",
    "            inputs_processed = inputs\n",
    "        weight = tf.Variable(tf.truncated_normal([dim,hiddens], stddev=0.1))\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[hiddens]))\n",
    "        print ('Layer  %d : Type = Full, Hidden = %d, Input dimension = %d, Flat = %d, Activation = %d' % (idx,hiddens,int(dim),int(flat),1-int(linear))\t)\n",
    "        if linear : return tf.add(tf.matmul(inputs_processed,weight),biases,name=str(idx)+'_fc')\n",
    "        ip = tf.add(tf.matmul(inputs_processed,weight),biases)\n",
    "        return tf.maximum(self.alpha*ip,ip,name=str(idx)+'_fc')\n",
    "\n",
    "def detect_from_cvmat(yolo,img):\n",
    "    yolo.h_img,yolo.w_img,_ = img.shape\n",
    "    img_resized = cv2.resize(img, (448, 448))\n",
    "    img_resized_np = np.asarray( img_resized )\n",
    "    inputs = np.zeros((1,448,448,3),dtype='float32')\n",
    "    inputs[0] = (img_resized_np/255.0)*2.0-1.0\n",
    "    in_dict = {yolo.x: inputs}\n",
    "    net_output = yolo.sess.run(yolo.fc_32,feed_dict=in_dict)\n",
    "\n",
    "    result = interpret_output(yolo, net_output[0])\n",
    "    yolo.result_list = result\n",
    "\n",
    "\n",
    "def detect_from_file(yolo,filename):\n",
    "    detect_from_cvmat(yolo, filename)\n",
    "\n",
    "\n",
    "def interpret_output(yolo,output):\n",
    "    probs = np.zeros((7,7,2,20))\n",
    "    class_probs = np.reshape(output[0:980],(7,7,20))\n",
    "    scales = np.reshape(output[980:1078],(7,7,2))\n",
    "    boxes = np.reshape(output[1078:],(7,7,2,4))\n",
    "    offset = np.transpose(np.reshape(np.array([np.arange(7)]*14),(2,7,7)),(1,2,0))\n",
    "\n",
    "    boxes[:,:,:,0] += offset\n",
    "    boxes[:,:,:,1] += np.transpose(offset,(1,0,2))\n",
    "    boxes[:,:,:,0:2] = boxes[:,:,:,0:2] / 7.0\n",
    "    boxes[:,:,:,2] = np.multiply(boxes[:,:,:,2],boxes[:,:,:,2])\n",
    "    boxes[:,:,:,3] = np.multiply(boxes[:,:,:,3],boxes[:,:,:,3])\n",
    "\n",
    "    boxes[:,:,:,0] *= yolo.w_img\n",
    "    boxes[:,:,:,1] *= yolo.h_img\n",
    "    boxes[:,:,:,2] *= yolo.w_img\n",
    "    boxes[:,:,:,3] *= yolo.h_img\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(20):\n",
    "            probs[:,:,i,j] = np.multiply(class_probs[:,:,j],scales[:,:,i])\n",
    "\n",
    "    filter_mat_probs = np.array(probs>=yolo.threshold,dtype='bool')\n",
    "    filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "    boxes_filtered = boxes[filter_mat_boxes[0],filter_mat_boxes[1],filter_mat_boxes[2]]\n",
    "    probs_filtered = probs[filter_mat_probs]\n",
    "    classes_num_filtered = np.argmax(filter_mat_probs,axis=3)[filter_mat_boxes[0],filter_mat_boxes[1],filter_mat_boxes[2]]\n",
    "\n",
    "    argsort = np.array(np.argsort(probs_filtered))[::-1]\n",
    "    boxes_filtered = boxes_filtered[argsort]\n",
    "    probs_filtered = probs_filtered[argsort]\n",
    "    classes_num_filtered = classes_num_filtered[argsort]\n",
    "\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        if probs_filtered[i] == 0 : continue\n",
    "        for j in range(i+1,len(boxes_filtered)):\n",
    "            if iou(boxes_filtered[i],boxes_filtered[j]) > yolo.iou_threshold :\n",
    "                probs_filtered[j] = 0.0\n",
    "\n",
    "    filter_iou = np.array(probs_filtered>0.0,dtype='bool')\n",
    "    boxes_filtered = boxes_filtered[filter_iou]\n",
    "    probs_filtered = probs_filtered[filter_iou]\n",
    "    classes_num_filtered = classes_num_filtered[filter_iou]\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        result.append([yolo.classes[classes_num_filtered[i]],boxes_filtered[i][0],boxes_filtered[i][1],boxes_filtered[i][2],boxes_filtered[i][3],probs_filtered[i]])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def draw_results(img,  yolo, fps):\n",
    "    img_cp = img.copy()\n",
    "    results = yolo.result_list\n",
    "\n",
    "    # draw the highlighted background\n",
    "   # img_cp = draw_background_highlight(img_cp, image_lane, yolo.w_img)\n",
    "\n",
    "    window_list = []\n",
    "    for i in range(len(results)):\n",
    "        x = int(results[i][1])\n",
    "        y = int(results[i][2])\n",
    "        w = int(results[i][3])//2\n",
    "        h = int(results[i][4])//2\n",
    "        cv2.rectangle(img_cp,(x-w,y-h),(x+w,y+h),(0,0,255),4)\n",
    "        cv2.rectangle(img_cp,(x-w,y-h-20),(x+w,y-h),(125,125,125),-1)\n",
    "        # cv2.putText(img_cp,results[i][0] + ' : %.2f' % results[i][5],(x-w+5,y-h-7),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,0),1)\n",
    "        cv2.putText(img_cp,results[i][0],(x-w+5,y-h-7),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,0),1)\n",
    "        if results[i][0] == \"car\" or results[i][0] == \"bus\":\n",
    "            window_list.append(((x-w,y-h),(x+w,y+h)))\n",
    "\n",
    "    # draw vehicle thumbnails\n",
    "    try:\n",
    "        draw_thumbnails(img_cp, img, window_list)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # draw speed\n",
    "    # draw_speed(img_cp, fps, yolo.w_img)\n",
    "\n",
    "    # draw lane status\n",
    "    #draw_lane_status(img_cp,lane_info)\n",
    "\n",
    "    return img_cp\n",
    "\n",
    "def iou(box1,box2):\n",
    "    tb = min(box1[0]+0.5*box1[2],box2[0]+0.5*box2[2])-max(box1[0]-0.5*box1[2],box2[0]-0.5*box2[2])\n",
    "    lr = min(box1[1]+0.5*box1[3],box2[1]+0.5*box2[3])-max(box1[1]-0.5*box1[3],box2[1]-0.5*box2[3])\n",
    "    if tb < 0 or lr < 0 : intersection = 0\n",
    "    else : intersection =  tb*lr\n",
    "    return intersection / (box1[2]*box1[3] + box2[2]*box2[3] - intersection)\n",
    "\n",
    "\n",
    "\n",
    "yolo = yolo_tf()\n",
    "\n",
    "def vehicle_detection_yolo(image):\n",
    "    # set the timer\n",
    "    start = timer()\n",
    "    detect_from_file(yolo, image)\n",
    "\n",
    "    # compute frame per second\n",
    "    fps = 1.0 / (timer() - start)\n",
    "    # draw visualization on frame\n",
    "    yolo_result = draw_results(image, yolo, fps)\n",
    "\n",
    "    return yolo_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_yolo(img):\n",
    "\n",
    "\n",
    "    #img_undist, img_lane_augmented, lane_info = lane_process(img)\n",
    "\n",
    "    output = vehicle_detection_yolo(img)\n",
    "    output_res = imresize(output, (720, 1280, 3))\n",
    "    \n",
    "\n",
    "    return output_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "\n",
    "# load the model json file \n",
    "json_file = open('model.json', 'r')\n",
    "json_model = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "# load the model from the json\n",
    "model = model_from_json(json_model)\n",
    "# load the wieghts of the model\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class Lane \n",
    "\n",
    "# Class to average lanes with\n",
    "class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.avg_fit = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image and predict the lane to be drawn from the model in G color\n",
    "\n",
    "def road_lines_image(image):\n",
    "    \n",
    "    img_arr = image\n",
    "    actual_image = imresize(img_arr, (720, 1280, 3))\n",
    "\n",
    "    # Get image ready for feeding into model\n",
    "    img = image\n",
    "    small_img_2 = imresize(img, (80, 160, 3))\n",
    "    \n",
    "    mask = np.zeros((small_img_2.shape[0], small_img_2.shape[1]), dtype=\"uint8\")\n",
    "    pts = np.array([[0, 80], [0, 40], [160, 40], [160, 80]], dtype=np.int32)\n",
    "    cv2.fillConvexPoly(mask, pts, 255)\n",
    "    \n",
    "    masked = cv2.bitwise_and(small_img_2, small_img_2, mask=mask)\n",
    "    small_img = masked[None, :, :, :]\n",
    "\n",
    "    # Make prediction with neural network (un-normalize value by multiplying by 255)\n",
    "    prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "    lanes = Lanes()\n",
    "    \n",
    "    # Add lane prediction to list for averaging\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    # Only using last five for average\n",
    "    if len(lanes.recent_fit) > 5:\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "\n",
    "    # Calculate average detection\n",
    "    lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "\n",
    "    # Generate fake R & B color dimensions, stack with G\n",
    "    blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "\n",
    "    # Re-size to match the original image\n",
    "    lane_image = imresize(lane_drawn, (720, 1280, 3))\n",
    "\n",
    "    # Merge the lane drawing onto the original image\n",
    "#     result = cv2.addWeighted(actual_image, 1, lane_image, 1, 0)\n",
    "\n",
    "    return lane_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proccess_frame(frame):\n",
    "    \n",
    "\n",
    "    img_lines = road_lines_image(frame)\n",
    "    img = pipeline_yolo(frame)\n",
    "    \n",
    "    result = cv2.addWeighted(img_lines, 1, img, 1, 0)\n",
    "    return result\n",
    "   \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"qwe\"\n",
    "\n",
    "# cv2.namedWindow(name)\n",
    "# cap=cv2.VideoCapture('my_test.mp4')\n",
    "\n",
    "# if cap.isOpened():\n",
    "    \n",
    "#     ret, frame = cap.read()\n",
    "# else: \n",
    "#     ret = False\n",
    "    \n",
    "# while ret: \n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "   \n",
    "           \n",
    "#     result = proccess_frame(frame)\n",
    "    \n",
    "#     cv2.imshow(name, result)\n",
    "\n",
    "    \n",
    "#     if cv2.waitKey(1) == 27: \n",
    "#         break\n",
    "# cv2.destroyWindow(name)\n",
    "\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video final_result_3.mp4\n",
      "[MoviePy] Writing video final_result_3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2833/2833 [33:11<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: final_result_3.mp4 \n",
      "\n",
      "Wall time: 33min 12s\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "output = 'final_result_3.mp4'\n",
    "clip1 = VideoFileClip(\"my_test.mp4\")\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(22,25)\n",
    "#clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "#clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "\n",
    "#clip1.save_frame(\"frame.jpeg\")\n",
    "#clip1 = clip1.fx(mve.vfx.rotate, lambda t: 90*t, expand=False)\n",
    "out_clip = clip1.fl_image(proccess_frame) #NOTE: this function expects color images!!\n",
    "%time out_clip.write_videofile(output, audio=False, verbose = True)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
